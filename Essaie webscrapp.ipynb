{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a3c430-fe4f-482d-b93d-a9a31b2415a5",
   "metadata": {},
   "source": [
    "# Webscrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2718fd8-8910-4a4c-80a5-cdbd8fede0d1",
   "metadata": {},
   "source": [
    "## Webscrapping basique avec unique package beautifulsoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37814a0-9dcb-459b-8fce-7d9e794b801b",
   "metadata": {},
   "source": [
    "### Installation des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6c195-dce4-4ee1-b646-aa3afbca6baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lxml\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1195a831-34b5-4e68-b137-57d13678e497",
   "metadata": {},
   "source": [
    "##### Dans un premier temps, on chercher à récupérer des informations sur la communication verte de l'entreprise Pfizer. Pour cela, on test le webscrapping sur différents sites internet : CNN, Europe PMC et Facebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52659ea2-1c56-4035-b048-2f1ffd72afc9",
   "metadata": {},
   "source": [
    "### CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c481b511-cfa8-4216-9915-ed65266ff99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"search__results-count\">\n",
       "<strong id=\"search__query\"></strong>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nom_entreprise = \"pfizer\"\n",
    "url = \"https://edition.cnn.com/search?q={0}&from=0&size=10&page=1&sort=newest&types=all&section=\".format(nom_entreprise)\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Utilisez response.text pour obtenir le contenu sous forme de chaîne de caractères\n",
    "    html_content = response.text\n",
    "\n",
    "    # Utilisez BeautifulSoup avec html_content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "else:\n",
    "    print(f\"La requête a échoué avec le code d'état {response.status_code}\")\n",
    "\n",
    "search_results_count_div = soup.find('div', class_='search__results-count')\n",
    "search_results_count_div\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4a4e5-0dc3-4b27-b5c0-dd8e9c0662d5",
   "metadata": {},
   "source": [
    "##### Conclusion : Aucun texte présent dans la balise recherchée..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc37310-6b6f-43a1-857a-a329937cb460",
   "metadata": {},
   "source": [
    "### EUROPE PMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74321c21-85bd-4d17-98f8-a49084b40787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balise <h2> non trouvée.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "numero_article = 10677964\n",
    "url = \"https://europepmc.org/article/PMC/PMC{0}\".format(numero_article)\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Utilisez response.text pour obtenir le contenu sous forme de chaîne de caractères\n",
    "    html_content = response.text\n",
    "\n",
    "    # Utilisez BeautifulSoup avec html_content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Récupérez la balise <h2> avec l'attribut id=\"article--free-full-text--header\"\n",
    "    h2_tag = soup.find('h2', {'id': 'article--free-full-text--header'})\n",
    "    \n",
    "    if h2_tag:\n",
    "        print(\"Balise <h2> trouvée :\", h2_tag.text)\n",
    "    else:\n",
    "        print(\"Balise <h2> non trouvée.\")\n",
    "    \n",
    "else:\n",
    "    print(f\"La requête a échoué avec le code d'état {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92996c49-e07c-41e1-889b-259f74ad3eb5",
   "metadata": {},
   "source": [
    "##### Conclusion : On ne trouve pas la basise qui permet d'afficher l'abstract de l'article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb4d7c-6bda-4b49-a9f2-47cf8758c86d",
   "metadata": {},
   "source": [
    "### Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df92da66-05c0-41ab-a897-ec8fa8097c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"https://www.facebook.com/Pfizer/?locale=fr_FR\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Utilisez response.text pour obtenir le contenu sous forme de chaîne de caractères\n",
    "    html_content = response.text\n",
    "\n",
    "    # Utilisez BeautifulSoup avec html_content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    all_post = soup.find_all('div', class_='x1yztbdb x1n2onr6 xh8yej3 x1ja2u2z') \n",
    "    \n",
    "else:\n",
    "    print(f\"La requête a échoué avec le code d'état {response.status_code}\")\n",
    "\n",
    "\n",
    "all_post\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f2b650-ff84-4988-b1d7-5a9c800277e9",
   "metadata": {},
   "source": [
    "##### Conclusion : On ne trouve pas les balises correspondant aux postes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275cc4e3-a9a8-444d-98de-ce309b3cc0c5",
   "metadata": {},
   "source": [
    "##### Possible problème de la méthode utilisée précedemment : les sites internet recherchés sont dynamiques. Pour résoudre ce problème, on essaye le package selinium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4858999-75d3-441f-9f5e-5f205df14aaf",
   "metadata": {},
   "source": [
    "## Webscrapping avec selinium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f8d1af-c7a2-47db-872f-1554731e8209",
   "metadata": {},
   "source": [
    "### Installation des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbc30321-0580-4122-acb6-3438590eb341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://dl.google.com/linux/chrome/deb stable InRelease\n",
      "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease                   \n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease   \n",
      "Hit:6 https://apt.postgresql.org/pub/repos/apt jammy-pgdg InRelease\n",
      "Fetched 229 kB in 2s (98.9 kB/s)                    \n",
      "Reading package lists... Done\n",
      "W: https://apt.postgresql.org/pub/repos/apt/dists/jammy-pgdg/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "libxi6 is already the newest version (2:1.8-1build1).\n",
      "libgconf-2-4 is already the newest version (3.2.6-7ubuntu2).\n",
      "unzip is already the newest version (6.0-26ubuntu3.1).\n",
      "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.5).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
      "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
      "--2023-12-20 09:44:51--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
      "Resolving dl.google.com (dl.google.com)... 64.233.166.136, 64.233.166.190, 64.233.166.91, ...\n",
      "Connecting to dl.google.com (dl.google.com)|64.233.166.136|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 104995956 (100M) [application/x-debian-package]\n",
      "Saving to: ‘/tmp/chrome.deb’\n",
      "\n",
      "/tmp/chrome.deb     100%[===================>] 100.13M  45.0MB/s    in 2.2s    \n",
      "\n",
      "2023-12-20 09:44:54 (45.0 MB/s) - ‘/tmp/chrome.deb’ saved [104995956/104995956]\n",
      "\n",
      "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease                 \n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease               \n",
      "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease               \n",
      "Hit:5 https://dl.google.com/linux/chrome/deb stable InRelease                  \n",
      "Hit:6 https://apt.postgresql.org/pub/repos/apt jammy-pgdg InRelease            \n",
      "Reading package lists... Done\n",
      "W: https://apt.postgresql.org/pub/repos/apt/dists/jammy-pgdg/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Note, selecting 'google-chrome-stable' instead of '/tmp/chrome.deb'\n",
      "google-chrome-stable is already the newest version (120.0.6099.109-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
      "Requirement already satisfied: chromedriver-autoinstaller in /opt/mamba/lib/python3.10/site-packages (0.6.3)\n",
      "Requirement already satisfied: selenium in /opt/mamba/lib/python3.10/site-packages (4.16.0)\n",
      "Requirement already satisfied: packaging>=23.1 in /opt/mamba/lib/python3.10/site-packages (from chromedriver-autoinstaller) (23.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/mamba/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.26.18)\n",
      "Requirement already satisfied: trio~=0.17 in /opt/mamba/lib/python3.10/site-packages (from selenium) (0.23.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /opt/mamba/lib/python3.10/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/mamba/lib/python3.10/site-packages (from selenium) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/mamba/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /opt/mamba/lib/python3.10/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /opt/mamba/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/mamba/lib/python3.10/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: webdriver_manager in /opt/mamba/lib/python3.10/site-packages (4.0.1)\n",
      "Requirement already satisfied: requests in /opt/mamba/lib/python3.10/site-packages (from webdriver_manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/mamba/lib/python3.10/site-packages (from webdriver_manager) (1.0.0)\n",
      "Requirement already satisfied: packaging in /opt/mamba/lib/python3.10/site-packages (from webdriver_manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver_manager) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver_manager) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver_manager) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.10/site-packages (from requests->webdriver_manager) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt install -y unzip xvfb libxi6 libgconf-2-4 -y\n",
    "!sudo apt install chromium-chromedriver -y\n",
    "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
    "\n",
    "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb -O /tmp/chrome.deb\n",
    "!sudo apt-get update\n",
    "!sudo -E apt-get install -y /tmp/chrome.deb\n",
    "!pip install chromedriver-autoinstaller selenium\n",
    "\n",
    "import chromedriver_autoinstaller\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "\n",
    "!pip install webdriver_manager\n",
    "\n",
    "import selenium\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "path_to_web_driver = ChromeDriverManager().install()\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "#chrome_options.add_argument('--verbose') \n",
    "\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "service = Service(executable_path=path_to_web_driver)\n",
    "\n",
    "browser = webdriver.Chrome(service=service,\n",
    "                           options=chrome_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be933355-df33-4597-a4fa-c45e4681b420",
   "metadata": {},
   "source": [
    "### CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "293c3a38-5ad7-41b7-b78b-6d14cec7ee14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head></head><body></body></html>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nom_entreprise = \"pfizer\"\n",
    "url = \"https://edition.cnn.com/search?q={0}&from=0&size=10&page=1&sort=newest&types=all&section=\".format(nom_entreprise)\n",
    "\n",
    "browser.get(url)\n",
    "\n",
    "# Obtenez le contenu de la page après que JavaScript ait pu mettre à jour le DOM\n",
    "html_content = browser.page_source\n",
    "\n",
    "# Utilisez BeautifulSoup comme précédemment\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "soup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a31b16f-4aff-4c86-a4f6-7d917082a45f",
   "metadata": {},
   "source": [
    "##### Conclusion : on fait pire qu'avec le package beautiful soup uniquement, on arrive pas à télécharger le code HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb105c6-c9e8-48a8-b819-8b7763008de8",
   "metadata": {},
   "source": [
    "### Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b821009d-9b6a-463c-8d1b-e12103697ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.facebook.com/Pfizer/?locale=fr_FR\"\n",
    "\n",
    "browser.get(url)\n",
    "\n",
    "# Obtenez le contenu de la page après que JavaScript ait pu mettre à jour le DOM\n",
    "html_content = browser.page_source\n",
    "\n",
    "# Utilisez BeautifulSoup comme précédemment\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "div_tags = soup.find_all('div', class_='x1yztbdb x1n2onr6 xh8yej3 x1ja2u2z')\n",
    "\n",
    "div_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9736ff73-160e-4f2f-9b52-1e7313a11a9c",
   "metadata": {},
   "source": [
    "##### Conclusion : On arrive toujours pas à récupérer les postes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed51fa2-6f29-4656-818d-d628ad48734c",
   "metadata": {},
   "source": [
    "### Europe PMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa808de4-f6b4-48de-995f-c18a8e590c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balise <h2> non trouvée.\n"
     ]
    }
   ],
   "source": [
    "numero_article = 10677964\n",
    "url = \"https://europepmc.org/article/PMC/PMC{0}\".format(numero_article)\n",
    "\n",
    "browser.get(url)\n",
    "\n",
    "# Obtenez le contenu de la page après que JavaScript ait pu mettre à jour le DOM\n",
    "html_content = browser.page_source\n",
    "\n",
    "# Utilisez BeautifulSoup comme précédemment\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "h2_tag = soup.find('h2', {'id': 'article--free-full-text--header'})\n",
    "\n",
    "if h2_tag:\n",
    "    print(\"Balise <h2> trouvée :\", h2_tag.text)\n",
    "else:\n",
    "    print(\"Balise <h2> non trouvée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b66118-3c05-414e-85d1-7afac8f11aae",
   "metadata": {},
   "source": [
    "##### Conclusion : pas d'amélioration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
