{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gc-N_bxnObwn",
    "outputId": "a8cb318d-08bc-4edd-be5c-c51a68b88c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in /opt/mamba/lib/python3.11/site-packages (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.24.2 in /opt/mamba/lib/python3.11/site-packages (from pyLDAvis) (1.26.3)\n",
      "Requirement already satisfied: scipy in /opt/mamba/lib/python3.11/site-packages (from pyLDAvis) (1.12.0)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /opt/mamba/lib/python3.11/site-packages (from pyLDAvis) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/mamba/lib/python3.11/site-packages (from pyLDAvis) (1.3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/mamba/lib/python3.11/site-packages (from pyLDAvis) (3.1.3)\n",
      "Requirement already satisfied: numexpr in /opt/mamba/lib/python3.11/site-packages (from pyLDAvis) (2.9.0)\n",
      "Requirement already satisfied: funcy in /opt/mamba/lib/python3.11/site-packages (from pyLDAvis) (2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /opt/mamba/lib/python3.11/site-packages (from pyLDAvis) (1.4.0)\n",
      "Requirement already satisfied: gensim in /opt/mamba/lib/python3.11/site-packages (from pyLDAvis) (4.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/mamba/lib/python3.11/site-packages (from pyLDAvis) (68.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/mamba/lib/python3.11/site-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/mamba/lib/python3.11/site-packages (from pandas>=2.0.0->pyLDAvis) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/mamba/lib/python3.11/site-packages (from pandas>=2.0.0->pyLDAvis) (2023.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/mamba/lib/python3.11/site-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/mamba/lib/python3.11/site-packages (from gensim->pyLDAvis) (6.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/mamba/lib/python3.11/site-packages (from jinja2->pyLDAvis) (2.1.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: nltk in /opt/mamba/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /opt/mamba/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/mamba/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/mamba/lib/python3.11/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/mamba/lib/python3.11/site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: wordcloud in /opt/mamba/lib/python3.11/site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/mamba/lib/python3.11/site-packages (from wordcloud) (1.26.3)\n",
      "Requirement already satisfied: pillow in /opt/mamba/lib/python3.11/site-packages (from wordcloud) (10.2.0)\n",
      "Requirement already satisfied: matplotlib in /opt/mamba/lib/python3.11/site-packages (from wordcloud) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/mamba/lib/python3.11/site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/mamba/lib/python3.11/site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/mamba/lib/python3.11/site-packages (from matplotlib->wordcloud) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/mamba/lib/python3.11/site-packages (from matplotlib->wordcloud) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.11/site-packages (from matplotlib->wordcloud) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/mamba/lib/python3.11/site-packages (from matplotlib->wordcloud) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/mamba/lib/python3.11/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: TextBlob in /opt/mamba/lib/python3.11/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/mamba/lib/python3.11/site-packages (from TextBlob) (3.8.1)\n",
      "Requirement already satisfied: click in /opt/mamba/lib/python3.11/site-packages (from nltk>=3.1->TextBlob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/mamba/lib/python3.11/site-packages (from nltk>=3.1->TextBlob) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/mamba/lib/python3.11/site-packages (from nltk>=3.1->TextBlob) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/mamba/lib/python3.11/site-packages (from nltk>=3.1->TextBlob) (4.66.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis\n",
    "!pip install nltk\n",
    "!pip install wordcloud\n",
    "!pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4mSOVtiqNKtK",
    "outputId": "06b329e1-9b0e-41db-8110-1b4af46507d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package genesis to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package genesis is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('genesis')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "#from IPython.display import display\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from collections import Counter\n",
    "from time import time\n",
    "# from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS as stopwords\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3JH1r8K5gMe"
   },
   "source": [
    "# Récupération des communications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qi6ZdjmlEK32"
   },
   "source": [
    "## Webscrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour voir notre travail de webscrapping, on pourra se référer au notebook nommé \"Essaie webscrapp.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Une première base de donnée : Une centaine d'articles du NYT et du WSJ avec le mot clef environnement sur les derniers jours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger à partir du fichier pickle\n",
    "data = pd.read_pickle('data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUFpMBn5EZk8"
   },
   "source": [
    "# Traitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAfkJlueLLR2"
   },
   "source": [
    "## Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Minuscule\n",
    "    text = text.lower()\n",
    "    # Supprimer la ponctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenization\n",
    "    words = word_tokenize(text)\n",
    "    # Suppression des stop-words\n",
    "    filtered_words = [word for word in words if word not in stopwords.words('english')]\n",
    "    # Lemmatisation\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in filtered_words])\n",
    "    \n",
    "    return lemmatized_output\n",
    "\n",
    "# Appliquer la fonction preprocess_text à la colonne 'Article'\n",
    "data['Preprocessed_Article'] = data['Article'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>Nombre de mots</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Titre</th>\n",
       "      <th>ID</th>\n",
       "      <th>Preprocessed_Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nMetropolitan Desk; SECTMB\\nCan an Ambitious ...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Nick Tabor</td>\n",
       "      <td>529</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Copyright 2023 The New York Times Company.  Al...</td>\n",
       "      <td>Document NYTF000020240104ejcv0000d</td>\n",
       "      <td>metropolitan desk sectmb ambitious public univ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMM\\nWhen Jim Brown and ...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Wesley Morris</td>\n",
       "      <td>422</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>When Jim Brown and Raquel Welch, Two Sexy Star...</td>\n",
       "      <td>Document NYTF000020231231ejcv0006h</td>\n",
       "      <td>magazine desk sectmm jim brown raquel welch tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nTalking During Movi...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>None</td>\n",
       "      <td>179</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Talking During Movies: Totally Evil or Part of...</td>\n",
       "      <td>Document NYTF000020231231ejcv00064\\n</td>\n",
       "      <td>magazine desk sectmk talking movie totally evi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nLet Kids Vote!\\n\\n4...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>None</td>\n",
       "      <td>454</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Let Kids Vote!</td>\n",
       "      <td>Document NYTF000020231231ejcv00063\\n</td>\n",
       "      <td>magazine desk sectmk let kid vote 454 word 31 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nAre We Doomed to Di...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Christina Caron</td>\n",
       "      <td>428</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Are We Doomed to Disagree?</td>\n",
       "      <td>Document NYTF000020231231ejcv0005z\\n</td>\n",
       "      <td>magazine desk sectmk doomed disagree 428 word ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nHello, Fourth Grade...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>None</td>\n",
       "      <td>319</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Hello, Fourth Graders! A Look Back at our Clas...</td>\n",
       "      <td>Document NYTF000020231231ejcv0005t\\n</td>\n",
       "      <td>magazine desk sectmk hello fourth grader look ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n\\nForeign Desk; SECTA\\n72 of Our Favorite Fa...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Times Insider</td>\n",
       "      <td>914</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>72 of Our Favorite Facts From 2023</td>\n",
       "      <td>Document NYTF000020231231ejcv0005r\\n</td>\n",
       "      <td>foreign desk secta 72 favorite fact 2023 time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n\\nMoney and Business/Financial Desk; SECTBU\\...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Kashmir Hill</td>\n",
       "      <td>811</td>\n",
       "      <td>Stalker Under Your Hood</td>\n",
       "      <td>The Stalker Under Your Hood</td>\n",
       "      <td>Document NYTF000020231231ejcv0005n\\n</td>\n",
       "      <td>money businessfinancial desk sectbu stalker ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\nBook Review Desk; SECTBR\\nPaperback Row\\n\\...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Shreya Chattopadhyay</td>\n",
       "      <td>431</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Paperback Row</td>\n",
       "      <td>Document NYTF000020231231ejcv0005g\\n</td>\n",
       "      <td>book review desk sectbr paperback row shreya c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n\\nNICHOLAS KRISTOF\\nEditorial Desk; SECTSR\\n...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Nicholas Kristof</td>\n",
       "      <td>976</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Humans Made Progress In 2023</td>\n",
       "      <td>Document NYTF000020231231ejcv00052\\n</td>\n",
       "      <td>nicholas kristof editorial desk sectsr human m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article              Date  \\\n",
       "0  \\nMetropolitan Desk; SECTMB\\nCan an Ambitious ...  31 December 2023   \n",
       "1  \\n\\nMagazine Desk; SECTMM\\nWhen Jim Brown and ...  31 December 2023   \n",
       "2  \\n\\nMagazine Desk; SECTMK\\nTalking During Movi...  31 December 2023   \n",
       "3  \\n\\nMagazine Desk; SECTMK\\nLet Kids Vote!\\n\\n4...  31 December 2023   \n",
       "4  \\n\\nMagazine Desk; SECTMK\\nAre We Doomed to Di...  31 December 2023   \n",
       "5  \\n\\nMagazine Desk; SECTMK\\nHello, Fourth Grade...  31 December 2023   \n",
       "6  \\n\\nForeign Desk; SECTA\\n72 of Our Favorite Fa...  31 December 2023   \n",
       "7  \\n\\nMoney and Business/Financial Desk; SECTBU\\...  31 December 2023   \n",
       "8  \\n\\nBook Review Desk; SECTBR\\nPaperback Row\\n\\...  31 December 2023   \n",
       "9  \\n\\nNICHOLAS KRISTOF\\nEditorial Desk; SECTSR\\n...  31 December 2023   \n",
       "\n",
       "                 Auteur  Nombre de mots                  Journal  \\\n",
       "0            Nick Tabor             529           New York Times   \n",
       "1         Wesley Morris             422           New York Times   \n",
       "2                  None             179           New York Times   \n",
       "3                  None             454           New York Times   \n",
       "4       Christina Caron             428           New York Times   \n",
       "5                  None             319           New York Times   \n",
       "6         Times Insider             914           New York Times   \n",
       "7          Kashmir Hill             811  Stalker Under Your Hood   \n",
       "8  Shreya Chattopadhyay             431           New York Times   \n",
       "9      Nicholas Kristof             976           New York Times   \n",
       "\n",
       "                                               Titre  \\\n",
       "0  Copyright 2023 The New York Times Company.  Al...   \n",
       "1  When Jim Brown and Raquel Welch, Two Sexy Star...   \n",
       "2  Talking During Movies: Totally Evil or Part of...   \n",
       "3                                     Let Kids Vote!   \n",
       "4                         Are We Doomed to Disagree?   \n",
       "5  Hello, Fourth Graders! A Look Back at our Clas...   \n",
       "6                 72 of Our Favorite Facts From 2023   \n",
       "7                        The Stalker Under Your Hood   \n",
       "8                                      Paperback Row   \n",
       "9                       Humans Made Progress In 2023   \n",
       "\n",
       "                                      ID  \\\n",
       "0     Document NYTF000020240104ejcv0000d   \n",
       "1     Document NYTF000020231231ejcv0006h   \n",
       "2  Document NYTF000020231231ejcv00064\\n    \n",
       "3  Document NYTF000020231231ejcv00063\\n    \n",
       "4  Document NYTF000020231231ejcv0005z\\n    \n",
       "5  Document NYTF000020231231ejcv0005t\\n    \n",
       "6  Document NYTF000020231231ejcv0005r\\n    \n",
       "7  Document NYTF000020231231ejcv0005n\\n    \n",
       "8  Document NYTF000020231231ejcv0005g\\n    \n",
       "9  Document NYTF000020231231ejcv00052\\n    \n",
       "\n",
       "                                Preprocessed_Article  \n",
       "0  metropolitan desk sectmb ambitious public univ...  \n",
       "1  magazine desk sectmm jim brown raquel welch tw...  \n",
       "2  magazine desk sectmk talking movie totally evi...  \n",
       "3  magazine desk sectmk let kid vote 454 word 31 ...  \n",
       "4  magazine desk sectmk doomed disagree 428 word ...  \n",
       "5  magazine desk sectmk hello fourth grader look ...  \n",
       "6  foreign desk secta 72 favorite fact 2023 time ...  \n",
       "7  money businessfinancial desk sectbu stalker ho...  \n",
       "8  book review desk sectbr paperback row shreya c...  \n",
       "9  nicholas kristof editorial desk sectsr human m...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA99lQ4VRIPj"
   },
   "source": [
    "## Analyse du sentiment des textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EApSppc3ROou"
   },
   "source": [
    "### Sentiment général"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6163XiZXN2i"
   },
   "source": [
    "Le score donné varie de -1 à 1 avec -1 comme la négativité maximale et 1 comme la positivité maximale. 0 pour dire que le texte est neutre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "id": "3cIikpC8RVPd",
    "outputId": "09d001bc-f208-4a1e-a073-8981d04cba49"
   },
   "outputs": [],
   "source": [
    "# Fonction pour calculer le sentiment\n",
    "def calculate_sentiment(text):\n",
    "    # Création d'une instance TextBlob\n",
    "    analysis = TextBlob(text)\n",
    "    # Retourner la polarité\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "# Appliquer la fonction au DataFrame\n",
    "data['Sentiment'] = data['Preprocessed_Article'].apply(calculate_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.080807\n",
       "1     0.096043\n",
       "2     0.129610\n",
       "3     0.068136\n",
       "4     0.081156\n",
       "        ...   \n",
       "95    0.017752\n",
       "96    0.062612\n",
       "97   -0.002605\n",
       "98    0.129660\n",
       "99   -0.021999\n",
       "Name: Sentiment, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJ7rBPftRPf3"
   },
   "source": [
    "### Sentiment environnemental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idéal serait de récupérer un dictionnaire pré existant, spécialisé dans l'évaluation de termes écologique, qui attribue une score à chaque terme. La difficulté à trouver ce type de dictionnaire nous mène dans un premier temps à creuser d'autres pistes de substitution. Nous verrons plus tard si nous réussissons à trouver un dictionnaire préexistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative aux dictionnaires pré-existants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problème pour l'amélioration du dictionnaire : on ne trouve pas de dictionnaire préexistant avec comme spécialité l'environnement. Deux options : \n",
    "\n",
    " - Améliorer notre dictionnaire fait main:\n",
    "   - Avantage : On peut contrôler le poid associé à chaque mot, dans la note\n",
    "   - Inconvéniant : COnstruction peu rigoureuse, on peut avoir oublié des mots\n",
    "  \n",
    " - Utiliser un dictionnaire généraliste :\n",
    "   - Avantage : Construction plus rigoureuse, moins de chance d'oublier certains termes\n",
    "   - Inconvénient : Pas de contrôle sur le poid des mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Le dictionnaire fait main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le moment, on ne trouve pas de dictionnaire pré-existant, dont chaque terme peut être associé à une note environnementale. On propose donc de construire nous même un dictionnaire, un en français et l'autre en anglais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un dictionnaire de termes environnementaux positifs\n",
    "Dico_env_fr = {\n",
    "    \"propre\": 1,\n",
    "    \"écologique\": 1,\n",
    "    \"durable\": 1,\n",
    "    \"vert\": 1,\n",
    "    \"économie d'énergie\": 1,\n",
    "    \"renouvelable\": 1,\n",
    "    \"responsable\": 1,\n",
    "    \"conservation\": 1,\n",
    "    \"biodiversité\": 1,\n",
    "    \"sain\": 1,\n",
    "    \"bio\": 1,\n",
    "    \"éco-friendly\": 1,\n",
    "    \"respectueux de l'environnement\": 1,\n",
    "    \"efficace\": 1,\n",
    "    \"innovant\": 1,\n",
    "    \"éthique\": 1,\n",
    "    \"équitable\": 1,\n",
    "    \"efficience\": 1,\n",
    "    \"responsabilité sociale\": 1,\n",
    "    \"sustainable\": 1,\n",
    "    \"solidaire\": 1,\n",
    "    \"propagation consciente\": 1,\n",
    "    \"soutenable\": 1,\n",
    "    \"énergie propre\": 1,\n",
    "    \"énergie renouvelable\": 1,\n",
    "    \"recyclage\": 1,\n",
    "    \"efficacité énergétique\": 1,\n",
    "    \"économie circulaire\": 1,\n",
    "    \"énergie solaire\": 1,\n",
    "    \"énergie éolienne\": 1,\n",
    "    \"régénération\": 1,\n",
    "    \"préservation\": 1,\n",
    "    \"restauration\": 1,\n",
    "    \"réhabilitation\": 1,\n",
    "    \"récupération\": 1,\n",
    "    \"restaurateur\": 1,\n",
    "    \"régénérateur\": 1,\n",
    "    \"revitalisation\": 1,\n",
    "    \"positif\": 1,\n",
    "    \"bénéfique\": 1,\n",
    "    \"valorisation\": 1,\n",
    "    \"épanouissement\": 1,\n",
    "    \"amélioration continue\": 1,\n",
    "    \"prospérité\": 1,\n",
    "    \"harmonie\": 1,\n",
    "    \"intégrité\": 1,\n",
    "    \"consommation responsable\": 1,\n",
    "    \"éco-responsable\": 1,\n",
    "    \"éco-conscient\": 1,\n",
    "    \"durabilité\": 1,\n",
    "    \"récupérable\": 1,\n",
    "    \"énergie verte\": 1,\n",
    "    \"effet de serre\": 1,\n",
    "    \"éco-efficace\": 1,\n",
    "    \"éco-innovation\": 1,\n",
    "    \"bien-être\": 1,\n",
    "    \"éco-design\": 1,\n",
    "    \"agroécologie\": 1,\n",
    "    \"permaculture\": 1,\n",
    "    \"éco-citoyen\": 1,\n",
    "    \"carbone neutre\": 1,\n",
    "    \"zéro déchet\": 1,\n",
    "    \"biologique\": 1,\n",
    "    \"éco-label\": 1,\n",
    "    \"mobilité durable\": 1,\n",
    "    \"éco-tourisme\": 1,\n",
    "    \"éco-habitat\": 1,\n",
    "    \"consommation consciente\": 1,\n",
    "\n",
    "    \"pollution\": -1,\n",
    "    \"déchet\": -1,\n",
    "    \"déforestation\": -1,\n",
    "    \"émissions de gaz à effet de serre\": -1,\n",
    "    \"contamination\": -1,\n",
    "    \"destructeur\": -1,\n",
    "    \"irresponsable\": -1,\n",
    "    \"gaspillage\": -1,\n",
    "    \"nuisible\": -1,\n",
    "    \"toxique\": -1,\n",
    "    \"détérioration\": -1,\n",
    "    \"dégradation\": -1,\n",
    "    \"dommageable\": -1,\n",
    "    \"préjudiciable\": -1,\n",
    "    \"périlleux\": -1,\n",
    "    \"inquiétant\": -1,\n",
    "    \"catastrophique\": -1,\n",
    "    \"catastrophe\": -1,\n",
    "    \"dangereux\": -1,\n",
    "    \"menace\": -1,\n",
    "    \"risque\": -1,\n",
    "    \"nocif\": -1,\n",
    "    \"néfaste\": -1,\n",
    "    \"inadéquat\": -1,\n",
    "    \"inapproprié\": -1,\n",
    "    \"inopportun\": -1,\n",
    "    \"nuire\": -1,\n",
    "    \"endommagement\": -1,\n",
    "    \"dommages\": -1,\n",
    "    \"polluant\": -1,\n",
    "    \"polluer\": -1,\n",
    "    \"détériorer\": -1,\n",
    "    \"perturbation\": -1,\n",
    "    \"irrespectueux\": -1,\n",
    "    \"malveillant\": -1,\n",
    "    \"dégât\": -1,\n",
    "    \"agressif\": -1,\n",
    "    \"ravageur\": -1,\n",
    "    \"gâcher\": -1,\n",
    "    \"perturber\": -1,\n",
    "    \"endommager\": -1,\n",
    "    \"irréparable\": -1,\n",
    "    \"toxicité\": -1,\n",
    "    \"inacceptable\": -1,\n",
    "    \"dommage écologique\": -1,\n",
    "    \"abattage illégal\": -1,\n",
    "    \"surconsommation\": -1,\n",
    "    \"pillage des ressources\": -1,\n",
    "    \"dégradation de l'environnement\": -1,\n",
    "    \"espace naturel détruit\": -1,\n",
    "    \"exploitation excessive\": -1,\n",
    "    \"surexploitation\": -1,\n",
    "    \"réchauffement climatique\": -1,\n",
    "    \"déni environnemental\": -1,\n",
    "}\n",
    "liste_negation = [\"pas\", \"non\",\"jamais\", \"aucun\", \"nul\", \"rien\", \"personne\", \"négatif\", \"sans\", \"plus\", \"moins\"]\n",
    "\n",
    "liste_annulation_negation = [\"responsable\",\"à l'origine\",\"la source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dico_env_en = {\n",
    "    \n",
    "    \"clean\": 1,\n",
    "    \"ecological\": 1,\n",
    "    \"sustainable\": 1,\n",
    "    \"green\": 1,\n",
    "    \"energy-efficient\": 1,\n",
    "    \"renewable\": 1,\n",
    "    \"responsible\": 1,\n",
    "    \"conservation\": 1,\n",
    "    \"biodiversity\": 1,\n",
    "    \"healthy\": 1,\n",
    "    \"organic\": 1,\n",
    "    \"eco-friendly\": 1,\n",
    "    \"environmentally friendly\": 1,\n",
    "    \"efficient\": 1,\n",
    "    \"innovative\": 1,\n",
    "    \"ethical\": 1,\n",
    "    \"fair\": 1,\n",
    "    \"efficiency\": 1,\n",
    "    \"social responsibility\": 1,\n",
    "    \"sustainable\": 1,\n",
    "    \"solidarity\": 1,\n",
    "    \"conscious spreading\": 1,\n",
    "    \"sustainable\": 1,\n",
    "    \"clean energy\": 1,\n",
    "    \"renewable energy\": 1,\n",
    "    \"recycling\": 1,\n",
    "    \"energy efficiency\": 1,\n",
    "    \"circular economy\": 1,\n",
    "    \"solar energy\": 1,\n",
    "    \"wind energy\": 1,\n",
    "    \"regeneration\": 1,\n",
    "    \"preservation\": 1,\n",
    "    \"restoration\": 1,\n",
    "    \"rehabilitation\": 1,\n",
    "    \"recovery\": 1,\n",
    "    \"restorer\": 1,\n",
    "    \"regenerator\": 1,\n",
    "    \"revitalization\": 1,\n",
    "    \"positive\": 1,\n",
    "    \"beneficial\": 1,\n",
    "    \"valorization\": 1,\n",
    "    \"fulfillment\": 1,\n",
    "    \"continuous improvement\": 1,\n",
    "    \"prosperity\": 1,\n",
    "    \"harmony\": 1,\n",
    "    \"integrity\": 1,\n",
    "    \"responsible consumption\": 1,\n",
    "    \"eco-responsible\": 1,\n",
    "    \"eco-conscious\": 1,\n",
    "    \"sustainability\": 1,\n",
    "    \"recoverable\": 1,\n",
    "    \"green energy\": 1,\n",
    "    \"greenhouse effect\": 1,\n",
    "    \"eco-efficient\": 1,\n",
    "    \"eco-innovation\": 1,\n",
    "    \"well-being\": 1,\n",
    "    \"eco-design\": 1,\n",
    "    \"agroecology\": 1,\n",
    "    \"permaculture\": 1,\n",
    "    \"eco-citizen\": 1,\n",
    "    \"carbon neutral\": 1,\n",
    "    \"zero waste\": 1,\n",
    "    \"organic\": 1,\n",
    "    \"eco-label\": 1,\n",
    "    \"sustainable mobility\": 1,\n",
    "    \"eco-tourism\": 1,\n",
    "    \"eco-habitat\": 1,\n",
    "    \"conscious consumption\": 1,\n",
    "    \n",
    "    \"pollution\": -1,\n",
    "    \"waste\": -1,\n",
    "    \"deforestation\": -1,\n",
    "    \"greenhouse gas emissions\": -1,\n",
    "    \"contamination\": -1,\n",
    "    \"destructive\": -1,\n",
    "    \"irresponsible\": -1,\n",
    "    \"wasteful\": -1,\n",
    "    \"harmful\": -1,\n",
    "    \"toxic\": -1,\n",
    "    \"deterioration\": -1,\n",
    "    \"degradation\": -1,\n",
    "    \"damaging\": -1,\n",
    "    \"harmful\": -1,\n",
    "    \"perilous\": -1,\n",
    "    \"worrisome\": -1,\n",
    "    \"catastrophic\": -1,\n",
    "    \"catastrophe\": -1,\n",
    "    \"dangerous\": -1,\n",
    "    \"threat\": -1,\n",
    "    \"risk\": -1,\n",
    "    \"hazardous\": -1,\n",
    "    \"harmful\": -1,\n",
    "    \"inappropriate\": -1,\n",
    "    \"inadequate\": -1,\n",
    "    \"inappropriate\": -1,\n",
    "    \"harm\": -1,\n",
    "    \"damage\": -1,\n",
    "    \"pollutant\": -1,\n",
    "    \"pollute\": -1,\n",
    "    \"deteriorate\": -1,\n",
    "    \"disruption\": -1,\n",
    "    \"disrespectful\": -1,\n",
    "    \"malevolent\": -1,\n",
    "    \"damage\": -1,\n",
    "    \"aggressive\": -1,\n",
    "    \"ravager\": -1,\n",
    "    \"spoil\": -1,\n",
    "    \"disturb\": -1,\n",
    "    \"damage\": -1,\n",
    "    \"irreparable\": -1,\n",
    "    \"toxicity\": -1,\n",
    "    \"unacceptable\": -1,\n",
    "    \"ecological damage\": -1,\n",
    "    \"illegal logging\": -1,\n",
    "    \"overconsumption\": -1,\n",
    "    \"resource plundering\": -1,\n",
    "    \"environmental degradation\": -1,\n",
    "    \"destroyed natural habitat\": -1,\n",
    "    \"excessive exploitation\": -1,\n",
    "    \"overexploitation\": -1,\n",
    "    \"climate change\": -1,\n",
    "    \"environmental denial\": -1,\n",
    "}\n",
    "\n",
    "negation_list = [\"not\", \"no\", \"never\", \"none\", \"nil\", \"nothing\", \"nobody\", \"negative\", \"without\", \"more\", \"less\"]\n",
    "\n",
    "negation_cancellation_list = [\"responsible\", \"originally\", \"source\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dictionnaire généraliste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'explorer la puissance d'un dictionnaire pré exsitant, nous faisant le choix de considérer un dictionnaire pré-existant, même s'il n'est pas spécialisé dans l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de sentiment pour le terme 'good':\n",
      "POS: 0.5, NEG: 0.0, OBJ: 0.5\n",
      "POS: 0.875, NEG: 0.0, OBJ: 0.125\n",
      "POS: 0.625, NEG: 0.0, OBJ: 0.375\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "POS: 0.75, NEG: 0.0, OBJ: 0.25\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "POS: 1.0, NEG: 0.0, OBJ: 0.0\n",
      "POS: 1.0, NEG: 0.0, OBJ: 0.0\n",
      "POS: 0.625, NEG: 0.0, OBJ: 0.375\n",
      "POS: 1.0, NEG: 0.0, OBJ: 0.0\n",
      "POS: 0.75, NEG: 0.0, OBJ: 0.25\n",
      "POS: 0.625, NEG: 0.0, OBJ: 0.375\n",
      "POS: 0.625, NEG: 0.0, OBJ: 0.375\n",
      "POS: 0.5, NEG: 0.0, OBJ: 0.5\n",
      "POS: 0.5, NEG: 0.0, OBJ: 0.5\n",
      "POS: 0.375, NEG: 0.0, OBJ: 0.625\n",
      "POS: 0.625, NEG: 0.0, OBJ: 0.375\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "POS: 0.625, NEG: 0.0, OBJ: 0.375\n",
      "POS: 0.75, NEG: 0.0, OBJ: 0.25\n",
      "POS: 0.75, NEG: 0.0, OBJ: 0.25\n",
      "POS: 0.875, NEG: 0.0, OBJ: 0.125\n",
      "POS: 0.5, NEG: 0.0, OBJ: 0.5\n",
      "POS: 0.375, NEG: 0.125, OBJ: 0.5\n",
      "POS: 0.75, NEG: 0.0, OBJ: 0.25\n",
      "POS: 0.375, NEG: 0.0, OBJ: 0.625\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "\n",
      "Scores de sentiment pour le terme 'bad':\n",
      "POS: 0.0, NEG: 0.875, OBJ: 0.125\n",
      "POS: 0.0, NEG: 0.625, OBJ: 0.375\n",
      "POS: 0.25, NEG: 0.25, OBJ: 0.5\n",
      "POS: 0.0, NEG: 0.75, OBJ: 0.25\n",
      "POS: 0.0, NEG: 0.75, OBJ: 0.25\n",
      "POS: 0.0, NEG: 0.625, OBJ: 0.375\n",
      "POS: 0.0, NEG: 0.75, OBJ: 0.25\n",
      "POS: 0.0, NEG: 0.625, OBJ: 0.375\n",
      "POS: 0.0, NEG: 0.5, OBJ: 0.5\n",
      "POS: 0.0, NEG: 0.75, OBJ: 0.25\n",
      "POS: 0.0, NEG: 1.0, OBJ: 0.0\n",
      "POS: 0.0, NEG: 0.375, OBJ: 0.625\n",
      "POS: 0.0, NEG: 0.75, OBJ: 0.25\n",
      "POS: 0.0, NEG: 0.75, OBJ: 0.25\n",
      "POS: 0.0, NEG: 0.75, OBJ: 0.25\n",
      "POS: 0.125, NEG: 0.25, OBJ: 0.625\n",
      "POS: 0.125, NEG: 0.25, OBJ: 0.625\n",
      "\n",
      "Scores de sentiment pour le terme 'environment':\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "\n",
      "Scores de sentiment pour le terme 'technology':\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "\n",
      "Scores de sentiment pour le terme 'greenhouse':\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "\n",
      "Scores de sentiment pour le terme 'gases':\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "POS: 0.0, NEG: 0.0, OBJ: 1.0\n",
      "\n",
      "Aucun synset trouvé pour le terme 'greenhouse gas'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')\n",
    "nltk.download('sentiwordnet')\n",
    "\n",
    "# Termes à examiner\n",
    "terms = [\"good\", \"bad\", \"environment\", \"technology\",\"greenhouse\",\"gases\",\"greenhouse gas\"]\n",
    "\n",
    "for term in terms:\n",
    "    # Obtenir les synsets associés au terme\n",
    "    synsets = list(swn.senti_synsets(term))\n",
    "\n",
    "    if synsets:\n",
    "        print(f\"Scores de sentiment pour le terme '{term}':\")\n",
    "        for synset in synsets:\n",
    "            print(f\"POS: {synset.pos_score()}, NEG: {synset.neg_score()}, OBJ: {synset.obj_score()}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"Aucun synset trouvé pour le terme '{term}'.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse : On a l'avantage d'avoir trois notes, qui représentent la part de positivité, de négativité et de neutralité du mot => Avancé par rapport à ce qu'on avait proposé. De plus, on considère qu'il y a plusieurs sens à chaque mot, d'où le fait qu'il y ait plusieurs évaluation pour chaque terme\n",
    "Avantage ; l'algorithme choisi la note du mot en fonction du contexte ?\n",
    "Problème : les coefficients ne sont pas forcément bons, par exemple, gases n'est jamais négatif, toujours neutre... pourquoi ?\n",
    "\n",
    "On test maintenant sur une phrase entière :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de la phrase: (0.16182795698924732, 0.020833333333333332, 0.6506720430107527)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def get_sentiment_scores(term):\n",
    "    synsets = list(swn.senti_synsets(term))\n",
    "    if synsets:\n",
    "        pos_score = sum(s.pos_score() for s in synsets) / len(synsets)\n",
    "        neg_score = sum(s.neg_score() for s in synsets) / len(synsets)\n",
    "        obj_score = sum(s.obj_score() for s in synsets) / len(synsets)\n",
    "\n",
    "        # Normaliser les scores\n",
    "        total_score = pos_score + neg_score + obj_score\n",
    "        if total_score != 0:\n",
    "            pos_score /= total_score\n",
    "            neg_score /= total_score\n",
    "            obj_score /= total_score\n",
    "\n",
    "        return pos_score, neg_score, obj_score\n",
    "    else:\n",
    "        return 0, 0, 0\n",
    "\n",
    "def analyze_sentence(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    scores = []\n",
    "\n",
    "    for token in tokens:\n",
    "        pos_score, neg_score, obj_score = get_sentiment_scores(token)\n",
    "        scores.append((pos_score, neg_score, obj_score))\n",
    "\n",
    "    # Calculer les scores moyens pour la phrase\n",
    "    avg_pos_score = sum(score[0] for score in scores) / len(scores)\n",
    "    avg_neg_score = sum(score[1] for score in scores) / len(scores)\n",
    "    avg_obj_score = sum(score[2] for score in scores) / len(scores)\n",
    "\n",
    "    return avg_pos_score, avg_neg_score, avg_obj_score\n",
    "\n",
    "# Exemple d'utilisation\n",
    "phrase = \"Clean technology promotes sustainable development.\"\n",
    "score_phrase = analyze_sentence(phrase)\n",
    "print(\"Score de la phrase:\", score_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque un taux de positivité de 16%, contre un taux de négativité de 2%, ainsi qu'un taux de neutralité de 65%. C'est un résultat relativement encourageant, étant donné qu'on a proposé une phrase à l'algorithme qui semblait être positive d'un point de vue environnemental.\n",
    "\n",
    "On compare ce score au score qu'a la négation de la phrase testée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de la phrase: (0.12241263440860216, 0.019791666666666666, 0.6077956989247312)\n"
     ]
    }
   ],
   "source": [
    "phrase = \"Clean technology doesn't promotes sustainable development.\"\n",
    "score_phrase = analyze_sentence(phrase)\n",
    "print(\"Score de la phrase:\", score_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse : Résultats moins encourageant. On observe en effet une baisse du taux de positivité, qui passe de 0.16 à 0.12, en revanche, le taux de négativité n'a pas augmenté, et reste faible, alors même que la phrase semble négative\n",
    "\n",
    "On test sur une autre phrase négative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de la phrase: (0.0078125, 0.046875, 0.1953125)\n"
     ]
    }
   ],
   "source": [
    "phrase = \"Pfizer destroyes environement.\"\n",
    "score_phrase = analyze_sentence(phrase)\n",
    "print(\"Score de la phrase:\", score_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score positif très faible, mais le négatif également. Est-ce intéressant de faire un rapport des deux ? On reste incertain quant à la significativité de la construction de notre note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_jSzcowY2Uy"
   },
   "source": [
    "On suppose que l'on a un dictionnaire `Dico_env` contenant les mots environnementaux, associés avec un score $\\in [-1,1]$. Par ex: {'pollution': -1, 'conservation': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rC0efxYkYiJA"
   },
   "source": [
    "#### Colonne environmental_sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wQrq34eQRM11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>Nombre de mots</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Titre</th>\n",
       "      <th>ID</th>\n",
       "      <th>Preprocessed_Article</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>environmental_sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nMetropolitan Desk; SECTMB\\nCan an Ambitious ...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Nick Tabor</td>\n",
       "      <td>529</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Copyright 2023 The New York Times Company.  Al...</td>\n",
       "      <td>Document NYTF000020240104ejcv0000d</td>\n",
       "      <td>metropolitan desk sectmb ambitious public univ...</td>\n",
       "      <td>0.080807</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMM\\nWhen Jim Brown and ...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Wesley Morris</td>\n",
       "      <td>422</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>When Jim Brown and Raquel Welch, Two Sexy Star...</td>\n",
       "      <td>Document NYTF000020231231ejcv0006h</td>\n",
       "      <td>magazine desk sectmm jim brown raquel welch tw...</td>\n",
       "      <td>0.096043</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nTalking During Movi...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>None</td>\n",
       "      <td>179</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Talking During Movies: Totally Evil or Part of...</td>\n",
       "      <td>Document NYTF000020231231ejcv00064\\n</td>\n",
       "      <td>magazine desk sectmk talking movie totally evi...</td>\n",
       "      <td>0.129610</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nLet Kids Vote!\\n\\n4...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>None</td>\n",
       "      <td>454</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Let Kids Vote!</td>\n",
       "      <td>Document NYTF000020231231ejcv00063\\n</td>\n",
       "      <td>magazine desk sectmk let kid vote 454 word 31 ...</td>\n",
       "      <td>0.068136</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nAre We Doomed to Di...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Christina Caron</td>\n",
       "      <td>428</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Are We Doomed to Disagree?</td>\n",
       "      <td>Document NYTF000020231231ejcv0005z\\n</td>\n",
       "      <td>magazine desk sectmk doomed disagree 428 word ...</td>\n",
       "      <td>0.081156</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nHello, Fourth Grade...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>None</td>\n",
       "      <td>319</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Hello, Fourth Graders! A Look Back at our Clas...</td>\n",
       "      <td>Document NYTF000020231231ejcv0005t\\n</td>\n",
       "      <td>magazine desk sectmk hello fourth grader look ...</td>\n",
       "      <td>0.153341</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n\\nForeign Desk; SECTA\\n72 of Our Favorite Fa...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Times Insider</td>\n",
       "      <td>914</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>72 of Our Favorite Facts From 2023</td>\n",
       "      <td>Document NYTF000020231231ejcv0005r\\n</td>\n",
       "      <td>foreign desk secta 72 favorite fact 2023 time ...</td>\n",
       "      <td>0.054622</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n\\nMoney and Business/Financial Desk; SECTBU\\...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Kashmir Hill</td>\n",
       "      <td>811</td>\n",
       "      <td>Stalker Under Your Hood</td>\n",
       "      <td>The Stalker Under Your Hood</td>\n",
       "      <td>Document NYTF000020231231ejcv0005n\\n</td>\n",
       "      <td>money businessfinancial desk sectbu stalker ho...</td>\n",
       "      <td>0.033175</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\nBook Review Desk; SECTBR\\nPaperback Row\\n\\...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Shreya Chattopadhyay</td>\n",
       "      <td>431</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Paperback Row</td>\n",
       "      <td>Document NYTF000020231231ejcv0005g\\n</td>\n",
       "      <td>book review desk sectbr paperback row shreya c...</td>\n",
       "      <td>0.127856</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n\\nNICHOLAS KRISTOF\\nEditorial Desk; SECTSR\\n...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Nicholas Kristof</td>\n",
       "      <td>976</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Humans Made Progress In 2023</td>\n",
       "      <td>Document NYTF000020231231ejcv00052\\n</td>\n",
       "      <td>nicholas kristof editorial desk sectsr human m...</td>\n",
       "      <td>0.011590</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article              Date  \\\n",
       "0  \\nMetropolitan Desk; SECTMB\\nCan an Ambitious ...  31 December 2023   \n",
       "1  \\n\\nMagazine Desk; SECTMM\\nWhen Jim Brown and ...  31 December 2023   \n",
       "2  \\n\\nMagazine Desk; SECTMK\\nTalking During Movi...  31 December 2023   \n",
       "3  \\n\\nMagazine Desk; SECTMK\\nLet Kids Vote!\\n\\n4...  31 December 2023   \n",
       "4  \\n\\nMagazine Desk; SECTMK\\nAre We Doomed to Di...  31 December 2023   \n",
       "5  \\n\\nMagazine Desk; SECTMK\\nHello, Fourth Grade...  31 December 2023   \n",
       "6  \\n\\nForeign Desk; SECTA\\n72 of Our Favorite Fa...  31 December 2023   \n",
       "7  \\n\\nMoney and Business/Financial Desk; SECTBU\\...  31 December 2023   \n",
       "8  \\n\\nBook Review Desk; SECTBR\\nPaperback Row\\n\\...  31 December 2023   \n",
       "9  \\n\\nNICHOLAS KRISTOF\\nEditorial Desk; SECTSR\\n...  31 December 2023   \n",
       "\n",
       "                 Auteur  Nombre de mots                  Journal  \\\n",
       "0            Nick Tabor             529           New York Times   \n",
       "1         Wesley Morris             422           New York Times   \n",
       "2                  None             179           New York Times   \n",
       "3                  None             454           New York Times   \n",
       "4       Christina Caron             428           New York Times   \n",
       "5                  None             319           New York Times   \n",
       "6         Times Insider             914           New York Times   \n",
       "7          Kashmir Hill             811  Stalker Under Your Hood   \n",
       "8  Shreya Chattopadhyay             431           New York Times   \n",
       "9      Nicholas Kristof             976           New York Times   \n",
       "\n",
       "                                               Titre  \\\n",
       "0  Copyright 2023 The New York Times Company.  Al...   \n",
       "1  When Jim Brown and Raquel Welch, Two Sexy Star...   \n",
       "2  Talking During Movies: Totally Evil or Part of...   \n",
       "3                                     Let Kids Vote!   \n",
       "4                         Are We Doomed to Disagree?   \n",
       "5  Hello, Fourth Graders! A Look Back at our Clas...   \n",
       "6                 72 of Our Favorite Facts From 2023   \n",
       "7                        The Stalker Under Your Hood   \n",
       "8                                      Paperback Row   \n",
       "9                       Humans Made Progress In 2023   \n",
       "\n",
       "                                      ID  \\\n",
       "0     Document NYTF000020240104ejcv0000d   \n",
       "1     Document NYTF000020231231ejcv0006h   \n",
       "2  Document NYTF000020231231ejcv00064\\n    \n",
       "3  Document NYTF000020231231ejcv00063\\n    \n",
       "4  Document NYTF000020231231ejcv0005z\\n    \n",
       "5  Document NYTF000020231231ejcv0005t\\n    \n",
       "6  Document NYTF000020231231ejcv0005r\\n    \n",
       "7  Document NYTF000020231231ejcv0005n\\n    \n",
       "8  Document NYTF000020231231ejcv0005g\\n    \n",
       "9  Document NYTF000020231231ejcv00052\\n    \n",
       "\n",
       "                                Preprocessed_Article  Sentiment  \\\n",
       "0  metropolitan desk sectmb ambitious public univ...   0.080807   \n",
       "1  magazine desk sectmm jim brown raquel welch tw...   0.096043   \n",
       "2  magazine desk sectmk talking movie totally evi...   0.129610   \n",
       "3  magazine desk sectmk let kid vote 454 word 31 ...   0.068136   \n",
       "4  magazine desk sectmk doomed disagree 428 word ...   0.081156   \n",
       "5  magazine desk sectmk hello fourth grader look ...   0.153341   \n",
       "6  foreign desk secta 72 favorite fact 2023 time ...   0.054622   \n",
       "7  money businessfinancial desk sectbu stalker ho...   0.033175   \n",
       "8  book review desk sectbr paperback row shreya c...   0.127856   \n",
       "9  nicholas kristof editorial desk sectsr human m...   0.011590   \n",
       "\n",
       "   environmental_sentiment_score  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "5                            0.0  \n",
       "6                            0.0  \n",
       "7                            0.0  \n",
       "8                            0.0  \n",
       "9                            0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_environmental_score(token_list, Dico_env):\n",
    "    score = 0\n",
    "    token_count = len(token_list)\n",
    "\n",
    "    for token in token_list:\n",
    "        if token in Dico_env:\n",
    "            score += Dico_env[token]\n",
    "\n",
    "    # Normalize the score to be between -1 and 1\n",
    "    if token_count > 0:\n",
    "        normalized_score = score / token_count\n",
    "        return max(min(normalized_score, 1), -1)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data['environmental_sentiment_score'] = data['Preprocessed_Article'].apply(lambda x: get_environmental_score(x, Dico_env_en))\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score environnemental semble être nul pour une partie des articles, on regarde si le score est parfois différent de 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La somme des valeurs absolue de la variable du score environnement est : 0.0\n"
     ]
    }
   ],
   "source": [
    "somme_valeurs_absolues = data['environmental_sentiment_score'].abs().sum()\n",
    "print(\"La somme des valeurs absolue de la variable du score environnement est :\", somme_valeurs_absolues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui pourrait expliquer le fait qu'aucune / très peu de texte, ai une note différente de 0, est le fait que les éléments du dictionnaire n'ont pas été prétraité (tokenisation etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clean': 1, 'ecological': 1, 'sustainable': 1, 'green': 1, 'energyefficient': 1, 'renewable': 1, 'responsible': 1, 'conservation': 1, 'biodiversity': 1, 'healthy': 1, 'organic': 1, 'ecofriendly': 1, 'environmentally friendly': 1, 'efficient': 1, 'innovative': 1, 'ethical': 1, 'fair': 1, 'efficiency': 1, 'social responsibility': 1, 'solidarity': 1, 'conscious spreading': 1, 'clean energy': 1, 'renewable energy': 1, 'recycling': 1, 'energy efficiency': 1, 'circular economy': 1, 'solar energy': 1, 'wind energy': 1, 'regeneration': 1, 'preservation': 1, 'restoration': 1, 'rehabilitation': 1, 'recovery': 1, 'restorer': 1, 'regenerator': 1, 'revitalization': 1, 'positive': 1, 'beneficial': 1, 'valorization': 1, 'fulfillment': 1, 'continuous improvement': 1, 'prosperity': 1, 'harmony': 1, 'integrity': 1, 'responsible consumption': 1, 'ecoresponsible': 1, 'ecoconscious': 1, 'sustainability': 1, 'recoverable': 1, 'green energy': 1, 'greenhouse effect': 1, 'ecoefficient': 1, 'ecoinnovation': 1, 'wellbeing': 1, 'ecodesign': 1, 'agroecology': 1, 'permaculture': 1, 'ecocitizen': 1, 'carbon neutral': 1, 'zero waste': 1, 'ecolabel': 1, 'sustainable mobility': 1, 'ecotourism': 1, 'ecohabitat': 1, 'conscious consumption': 1, 'pollution': -1, 'waste': -1, 'deforestation': -1, 'greenhouse gas emission': -1, 'contamination': -1, 'destructive': -1, 'irresponsible': -1, 'wasteful': -1, 'harmful': -1, 'toxic': -1, 'deterioration': -1, 'degradation': -1, 'damaging': -1, 'perilous': -1, 'worrisome': -1, 'catastrophic': -1, 'catastrophe': -1, 'dangerous': -1, 'threat': -1, 'risk': -1, 'hazardous': -1, 'inappropriate': -1, 'inadequate': -1, 'harm': -1, 'damage': -1, 'pollutant': -1, 'pollute': -1, 'deteriorate': -1, 'disruption': -1, 'disrespectful': -1, 'malevolent': -1, 'aggressive': -1, 'ravager': -1, 'spoil': -1, 'disturb': -1, 'irreparable': -1, 'toxicity': -1, 'unacceptable': -1, 'ecological damage': -1, 'illegal logging': -1, 'overconsumption': -1, 'resource plundering': -1, 'environmental degradation': -1, 'destroyed natural habitat': -1, 'excessive exploitation': -1, 'overexploitation': -1, 'climate change': -1, 'environmental denial': -1}\n",
      "{'propre': 1, 'écologique': 1, 'durable': 1, 'vert': 1, 'économie dénergie': 1, 'renouvelable': 1, 'responsable': 1, 'conservation': 1, 'biodiversité': 1, 'sain': 1, 'bio': 1, 'écofriendly': 1, 'respectueux de lenvironnement': 1, 'efficace': 1, 'innovant': 1, 'éthique': 1, 'équitable': 1, 'efficience': 1, 'responsabilité sociale': 1, 'sustainable': 1, 'solidaire': 1, 'propagation consciente': 1, 'soutenable': 1, 'énergie propre': 1, 'énergie renouvelable': 1, 'recyclage': 1, 'efficacité énergétique': 1, 'économie circulaire': 1, 'énergie solaire': 1, 'énergie éolienne': 1, 'régénération': 1, 'préservation': 1, 'restauration': 1, 'réhabilitation': 1, 'récupération': 1, 'restaurateur': 1, 'régénérateur': 1, 'revitalisation': 1, 'positif': 1, 'bénéfique': 1, 'valorisation': 1, 'épanouissement': 1, 'amélioration continue': 1, 'prospérité': 1, 'harmonie': 1, 'intégrité': 1, 'consommation responsable': 1, 'écoresponsable': 1, 'écoconscient': 1, 'durabilité': 1, 'récupérable': 1, 'énergie verte': 1, 'effet de serre': 1, 'écoefficace': 1, 'écoinnovation': 1, 'bienêtre': 1, 'écodesign': 1, 'agroécologie': 1, 'permaculture': 1, 'écocitoyen': 1, 'carbone neutre': 1, 'zéro déchet': 1, 'biologique': 1, 'écolabel': 1, 'mobilité durable': 1, 'écotourisme': 1, 'écohabitat': 1, 'consommation consciente': 1, 'pollution': -1, 'déchet': -1, 'déforestation': -1, 'émissions de gaz à effet de serre': -1, 'contamination': -1, 'destructeur': -1, 'irresponsable': -1, 'gaspillage': -1, 'nuisible': -1, 'toxique': -1, 'détérioration': -1, 'dégradation': -1, 'dommageable': -1, 'préjudiciable': -1, 'périlleux': -1, 'inquiétant': -1, 'catastrophique': -1, 'catastrophe': -1, 'dangereux': -1, 'menace': -1, 'risque': -1, 'nocif': -1, 'néfaste': -1, 'inadéquat': -1, 'inapproprié': -1, 'inopportun': -1, 'nuire': -1, 'endommagement': -1, 'dommages': -1, 'polluant': -1, 'polluer': -1, 'détériorer': -1, 'perturbation': -1, 'irrespectueux': -1, 'malveillant': -1, 'dégât': -1, 'agressif': -1, 'ravageur': -1, 'gâcher': -1, 'perturber': -1, 'endommager': -1, 'irréparable': -1, 'toxicité': -1, 'inacceptable': -1, 'dommage écologique': -1, 'abattage illégal': -1, 'surconsommation': -1, 'pillage de ressources': -1, 'dégradation de lenvironnement': -1, 'espace naturel détruit': -1, 'exploitation excessive': -1, 'surexploitation': -1, 'réchauffement climatique': -1, 'déni environnemental': -1}\n"
     ]
    }
   ],
   "source": [
    "# Appliquer la fonction preprocess_text aux clés du dictionnaire\n",
    "preprocessed_dict_en = {preprocess_text(key): value for key, value in Dico_env_en.items()}\n",
    "preprocessed_dict_fr = {preprocess_text(key): value for key, value in Dico_env_fr.items()}\n",
    "\n",
    "\n",
    "# Affichage du dictionnaire après prétraitement des clés\n",
    "print(preprocessed_dict_en)\n",
    "print(preprocessed_dict_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, il ne semble pas que la tokenisation ou la lemnisation ait fonctionné..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>Nombre de mots</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Titre</th>\n",
       "      <th>ID</th>\n",
       "      <th>Preprocessed_Article</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>environmental_sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nMetropolitan Desk; SECTMB\\nCan an Ambitious ...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Nick Tabor</td>\n",
       "      <td>529</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Copyright 2023 The New York Times Company.  Al...</td>\n",
       "      <td>Document NYTF000020240104ejcv0000d</td>\n",
       "      <td>metropolitan desk sectmb ambitious public univ...</td>\n",
       "      <td>0.080807</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMM\\nWhen Jim Brown and ...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Wesley Morris</td>\n",
       "      <td>422</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>When Jim Brown and Raquel Welch, Two Sexy Star...</td>\n",
       "      <td>Document NYTF000020231231ejcv0006h</td>\n",
       "      <td>magazine desk sectmm jim brown raquel welch tw...</td>\n",
       "      <td>0.096043</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nTalking During Movi...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>None</td>\n",
       "      <td>179</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Talking During Movies: Totally Evil or Part of...</td>\n",
       "      <td>Document NYTF000020231231ejcv00064\\n</td>\n",
       "      <td>magazine desk sectmk talking movie totally evi...</td>\n",
       "      <td>0.129610</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nLet Kids Vote!\\n\\n4...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>None</td>\n",
       "      <td>454</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Let Kids Vote!</td>\n",
       "      <td>Document NYTF000020231231ejcv00063\\n</td>\n",
       "      <td>magazine desk sectmk let kid vote 454 word 31 ...</td>\n",
       "      <td>0.068136</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nAre We Doomed to Di...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Christina Caron</td>\n",
       "      <td>428</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Are We Doomed to Disagree?</td>\n",
       "      <td>Document NYTF000020231231ejcv0005z\\n</td>\n",
       "      <td>magazine desk sectmk doomed disagree 428 word ...</td>\n",
       "      <td>0.081156</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nHello, Fourth Grade...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>None</td>\n",
       "      <td>319</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Hello, Fourth Graders! A Look Back at our Clas...</td>\n",
       "      <td>Document NYTF000020231231ejcv0005t\\n</td>\n",
       "      <td>magazine desk sectmk hello fourth grader look ...</td>\n",
       "      <td>0.153341</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n\\nForeign Desk; SECTA\\n72 of Our Favorite Fa...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Times Insider</td>\n",
       "      <td>914</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>72 of Our Favorite Facts From 2023</td>\n",
       "      <td>Document NYTF000020231231ejcv0005r\\n</td>\n",
       "      <td>foreign desk secta 72 favorite fact 2023 time ...</td>\n",
       "      <td>0.054622</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n\\nMoney and Business/Financial Desk; SECTBU\\...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Kashmir Hill</td>\n",
       "      <td>811</td>\n",
       "      <td>Stalker Under Your Hood</td>\n",
       "      <td>The Stalker Under Your Hood</td>\n",
       "      <td>Document NYTF000020231231ejcv0005n\\n</td>\n",
       "      <td>money businessfinancial desk sectbu stalker ho...</td>\n",
       "      <td>0.033175</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\nBook Review Desk; SECTBR\\nPaperback Row\\n\\...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Shreya Chattopadhyay</td>\n",
       "      <td>431</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Paperback Row</td>\n",
       "      <td>Document NYTF000020231231ejcv0005g\\n</td>\n",
       "      <td>book review desk sectbr paperback row shreya c...</td>\n",
       "      <td>0.127856</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n\\nNICHOLAS KRISTOF\\nEditorial Desk; SECTSR\\n...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Nicholas Kristof</td>\n",
       "      <td>976</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Humans Made Progress In 2023</td>\n",
       "      <td>Document NYTF000020231231ejcv00052\\n</td>\n",
       "      <td>nicholas kristof editorial desk sectsr human m...</td>\n",
       "      <td>0.011590</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article              Date  \\\n",
       "0  \\nMetropolitan Desk; SECTMB\\nCan an Ambitious ...  31 December 2023   \n",
       "1  \\n\\nMagazine Desk; SECTMM\\nWhen Jim Brown and ...  31 December 2023   \n",
       "2  \\n\\nMagazine Desk; SECTMK\\nTalking During Movi...  31 December 2023   \n",
       "3  \\n\\nMagazine Desk; SECTMK\\nLet Kids Vote!\\n\\n4...  31 December 2023   \n",
       "4  \\n\\nMagazine Desk; SECTMK\\nAre We Doomed to Di...  31 December 2023   \n",
       "5  \\n\\nMagazine Desk; SECTMK\\nHello, Fourth Grade...  31 December 2023   \n",
       "6  \\n\\nForeign Desk; SECTA\\n72 of Our Favorite Fa...  31 December 2023   \n",
       "7  \\n\\nMoney and Business/Financial Desk; SECTBU\\...  31 December 2023   \n",
       "8  \\n\\nBook Review Desk; SECTBR\\nPaperback Row\\n\\...  31 December 2023   \n",
       "9  \\n\\nNICHOLAS KRISTOF\\nEditorial Desk; SECTSR\\n...  31 December 2023   \n",
       "\n",
       "                 Auteur  Nombre de mots                  Journal  \\\n",
       "0            Nick Tabor             529           New York Times   \n",
       "1         Wesley Morris             422           New York Times   \n",
       "2                  None             179           New York Times   \n",
       "3                  None             454           New York Times   \n",
       "4       Christina Caron             428           New York Times   \n",
       "5                  None             319           New York Times   \n",
       "6         Times Insider             914           New York Times   \n",
       "7          Kashmir Hill             811  Stalker Under Your Hood   \n",
       "8  Shreya Chattopadhyay             431           New York Times   \n",
       "9      Nicholas Kristof             976           New York Times   \n",
       "\n",
       "                                               Titre  \\\n",
       "0  Copyright 2023 The New York Times Company.  Al...   \n",
       "1  When Jim Brown and Raquel Welch, Two Sexy Star...   \n",
       "2  Talking During Movies: Totally Evil or Part of...   \n",
       "3                                     Let Kids Vote!   \n",
       "4                         Are We Doomed to Disagree?   \n",
       "5  Hello, Fourth Graders! A Look Back at our Clas...   \n",
       "6                 72 of Our Favorite Facts From 2023   \n",
       "7                        The Stalker Under Your Hood   \n",
       "8                                      Paperback Row   \n",
       "9                       Humans Made Progress In 2023   \n",
       "\n",
       "                                      ID  \\\n",
       "0     Document NYTF000020240104ejcv0000d   \n",
       "1     Document NYTF000020231231ejcv0006h   \n",
       "2  Document NYTF000020231231ejcv00064\\n    \n",
       "3  Document NYTF000020231231ejcv00063\\n    \n",
       "4  Document NYTF000020231231ejcv0005z\\n    \n",
       "5  Document NYTF000020231231ejcv0005t\\n    \n",
       "6  Document NYTF000020231231ejcv0005r\\n    \n",
       "7  Document NYTF000020231231ejcv0005n\\n    \n",
       "8  Document NYTF000020231231ejcv0005g\\n    \n",
       "9  Document NYTF000020231231ejcv00052\\n    \n",
       "\n",
       "                                Preprocessed_Article  Sentiment  \\\n",
       "0  metropolitan desk sectmb ambitious public univ...   0.080807   \n",
       "1  magazine desk sectmm jim brown raquel welch tw...   0.096043   \n",
       "2  magazine desk sectmk talking movie totally evi...   0.129610   \n",
       "3  magazine desk sectmk let kid vote 454 word 31 ...   0.068136   \n",
       "4  magazine desk sectmk doomed disagree 428 word ...   0.081156   \n",
       "5  magazine desk sectmk hello fourth grader look ...   0.153341   \n",
       "6  foreign desk secta 72 favorite fact 2023 time ...   0.054622   \n",
       "7  money businessfinancial desk sectbu stalker ho...   0.033175   \n",
       "8  book review desk sectbr paperback row shreya c...   0.127856   \n",
       "9  nicholas kristof editorial desk sectsr human m...   0.011590   \n",
       "\n",
       "   environmental_sentiment_score  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "5                            0.0  \n",
       "6                            0.0  \n",
       "7                            0.0  \n",
       "8                            0.0  \n",
       "9                            0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_environmental_score(token_list, Dico_env):\n",
    "    score = 0\n",
    "    token_count = len(token_list)\n",
    "\n",
    "    for token in token_list:\n",
    "        if token in Dico_env:\n",
    "            score += Dico_env[token]\n",
    "\n",
    "    # Normalize the score to be between -1 and 1\n",
    "    if token_count > 0:\n",
    "        normalized_score = score / token_count\n",
    "        return max(min(normalized_score, 1), -1)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data['environmental_sentiment_score'] = data['Preprocessed_Article'].apply(lambda x: get_environmental_score(x, preprocessed_dict_en))\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La somme des valeurs absolue de la variable du score environnement est : 0.0\n"
     ]
    }
   ],
   "source": [
    "somme_valeurs_absolues = data['environmental_sentiment_score'].abs().sum()\n",
    "print(\"La somme des valeurs absolue de la variable du score environnement est :\", somme_valeurs_absolues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Est ce que les éléments de la colonne Processed_Article contiennent une liste de mots qui composent l'article, ou bien c'est un seul élément (une grande chaine de charactère) ? Si c'est une grande chaîne de caractère, ça peut poser problème car pour construire la variable de score envorionnementale, on compare un mot à un texte => Donc le score environnemental reste nul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metropolitan desk sectmb ambitious public university place nick tabor 1529 word 31 december 2023 new york time nytf late edition final 4 english copyright 2023 new york time company right reserved stony brook university one two state school designated flagship aggressively fundraised recruited student shortly became governor new york kathy hochul made announcement caught highereducation world guard state generally regarded public university equal would start treating two university flagship surprising still choice elite label didnt include binghamton university often regarded new york top academic public university instead governor said distinction would go stony brook university long island university buffalo hometown leader stony brook promotion wasnt surprise next step yearslong campaign transform institution wellregarded regional school nearly half student long island globally renowned research institution administrator like say berkeley east flagship designation honorary rhetorical power anything else stony brook president maurie mcinnis said interview two year since announcement stony brook moved aggressively live new title advertising new status widely recruit student donor place u news world report college ranking jumped 93 58 secured fund nearly triple endowment including one largest donation university american history right develop climate solution lab large chunk real estate governor island beating new york largest prestigious institution observer wonder whether school advancement come cost equity suggest school state university new york system could get short shrift also worry stony brook 16 percent student come family bottom fifth american income level could transformed school elite every sense john friedman chair brown university economics department done extensive research role university promoting social mobility said kind drift inevitable think making selective make difficult bring number lowincome student suny system exists today established 1950s cobbled together teacher college agricultural school existing institution including university buffalo part original aim establish highcaliber public university state new yorker would far one stony brook opened 1957 part effort relatively modern design far cry stately neogothic style ivy league school reflecting recent origin concentration science technology half student commuter never known robust campus culture even early day leader stony brook buffalo ambitious still stony brook became known success helping poor student 2017 ranked third best nation social mobility according metric designed friedman colleague half student lowincome household end top fifth earner nationally getting degree equity always part stony brook dna m mcinnis put said school often attracted faculty appreciate public service mission stony brook assembled committee choose new president late 2019 leadership saw chance revive global ambition said rich gelfond chief executive imax corporation chair university fundraising arm said trustee among jim simon taught math department making billion hedge fund manager sought administrator understood lever power public higher education m mcinnis art historian background joined 2020 savvy veteran two america prestigious public university university virginia university texas austin really knew navigate world mr gelfond said early m mcinnis persuaded donor set 75 million fund could personally use strategic opportunity summer 2021 city announced launching global competition governor island climate center m mcinnis drew 7 million assemble detailed proposal stony brook recruited number institution including georgia institute technology pratt institute ibm sign partner saw immediately knew something compete frankly win said meantime governor bestowed flagship label choosing state two big research university receive legislator representing binghamton albany dismayed least five signed letter governor expressing concern decision would put local university material disadvantage past february m hochul said wanted state provide 50 percent match donation made endowment new york four largest university also included binghamton albany legislature passed matching plan spring four week later simon wife marilyn simon announced donating 500 million stony brook believed largest unrestricted donation american public university ever received stony brook foundation university fundraising arm lobbied state matching program mr gelfond said knowing would help appeal donor used program persuade simon make historic gift united university profession union represents professor employee suny concerned new flagship designation lead neglect smaller institution like community college technical school said frederick kowal union statewide president said occurred state like california public university grouped distinct tier part leader stony brook suny tend argue zerosum game stony brook bring federal research dollar could raise profile suny system overall spur economic development boot said john king suny chancellor statement spokeswoman simon foundation anastasia greenebaum said regard support stony brook giving school advantage state school creating tier one suny school receiving additional financial support may excel lower lessen school said improvement university ultimately benefited new yorkers attend prospective student parent also seem taking note stony brook growing stature current academic year university received 50000 freshman application 24 percent increase year freshman class also largest ever 3567 student application also risen suny school thanks part application fee waiver state introduced last year one hand school growing popularity sign success hand raise concern balancing growth inclusiveness there ceiling term growth even campus like stony brook mr kowal union president said big get talking ohio state ten thousand student talking chapel hill smaller point becomes selective stony brook administrator noted last decade lowincome student enrolled even admission become selective m mcinnis said focused immediate concern money flow said first priority hiring faculty upgrading oldest campus facility next president love thank said whether growth could compromise school already established success engine social mobility m mcinnis said guess thats something future leader going keep eye stony brook university long island aim globally renowned research institution maurie mcinnis president point public service mission photograph anastassia whitty new york time article appeared print page mb4 document nytf000020240104ejcv0000d'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Preprocessed_Article'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Preprocessed_Article'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les élements de la variable Processed_Article est donc une longue et unique chaîne de caractère. On créer un code qui prends une chaîne de caractère en entrée, et qui renvoie une liste de mots qui composent cet article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [metropolitan, desk, sectmb, ambitious, public...\n",
       "1     [magazine, desk, sectmm, jim, brown, raquel, w...\n",
       "2     [magazine, desk, sectmk, talking, movie, total...\n",
       "3     [magazine, desk, sectmk, let, kid, vote, 454, ...\n",
       "4     [magazine, desk, sectmk, doomed, disagree, 428...\n",
       "                            ...                        \n",
       "95    [global, health, science, desk, sectd, new, ho...\n",
       "96    [foreign, desk, secta, hotel, intended, house,...\n",
       "97    [businessfinancial, desk, sectb, eu, open, inv...\n",
       "98    [trilobite, science, desk, sectd, proof, wine,...\n",
       "99    [impossible, energy, transition, mario, loyola...\n",
       "Name: Preprocessed_Article_split, Length: 100, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mots_dans_article(article):\n",
    "    # Diviser l'article en mots en utilisant l'espace comme délimiteur\n",
    "    mots = article.split()\n",
    "\n",
    "    # Retourner la liste des mots\n",
    "    return mots\n",
    "\n",
    "data['Preprocessed_Article_split']=data['Preprocessed_Article'].apply(lambda x: mots_dans_article(x))\n",
    "\n",
    "data['Preprocessed_Article_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Auteur</th>\n",
       "      <th>Nombre de mots</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Titre</th>\n",
       "      <th>ID</th>\n",
       "      <th>Preprocessed_Article</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>environmental_sentiment_score</th>\n",
       "      <th>Preprocessed_Article_split</th>\n",
       "      <th>environmental_sentiment_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nMetropolitan Desk; SECTMB\\nCan an Ambitious ...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Nick Tabor</td>\n",
       "      <td>529</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Copyright 2023 The New York Times Company.  Al...</td>\n",
       "      <td>Document NYTF000020240104ejcv0000d</td>\n",
       "      <td>metropolitan desk sectmb ambitious public univ...</td>\n",
       "      <td>0.080807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[metropolitan, desk, sectmb, ambitious, public...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMM\\nWhen Jim Brown and ...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Wesley Morris</td>\n",
       "      <td>422</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>When Jim Brown and Raquel Welch, Two Sexy Star...</td>\n",
       "      <td>Document NYTF000020231231ejcv0006h</td>\n",
       "      <td>magazine desk sectmm jim brown raquel welch tw...</td>\n",
       "      <td>0.096043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[magazine, desk, sectmm, jim, brown, raquel, w...</td>\n",
       "      <td>0.001267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nTalking During Movi...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>None</td>\n",
       "      <td>179</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Talking During Movies: Totally Evil or Part of...</td>\n",
       "      <td>Document NYTF000020231231ejcv00064\\n</td>\n",
       "      <td>magazine desk sectmk talking movie totally evi...</td>\n",
       "      <td>0.129610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[magazine, desk, sectmk, talking, movie, total...</td>\n",
       "      <td>-0.007692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nLet Kids Vote!\\n\\n4...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>None</td>\n",
       "      <td>454</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Let Kids Vote!</td>\n",
       "      <td>Document NYTF000020231231ejcv00063\\n</td>\n",
       "      <td>magazine desk sectmk let kid vote 454 word 31 ...</td>\n",
       "      <td>0.068136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[magazine, desk, sectmk, let, kid, vote, 454, ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nAre We Doomed to Di...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Christina Caron</td>\n",
       "      <td>428</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Are We Doomed to Disagree?</td>\n",
       "      <td>Document NYTF000020231231ejcv0005z\\n</td>\n",
       "      <td>magazine desk sectmk doomed disagree 428 word ...</td>\n",
       "      <td>0.081156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[magazine, desk, sectmk, doomed, disagree, 428...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\nMagazine Desk; SECTMK\\nHello, Fourth Grade...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>None</td>\n",
       "      <td>319</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Hello, Fourth Graders! A Look Back at our Clas...</td>\n",
       "      <td>Document NYTF000020231231ejcv0005t\\n</td>\n",
       "      <td>magazine desk sectmk hello fourth grader look ...</td>\n",
       "      <td>0.153341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[magazine, desk, sectmk, hello, fourth, grader...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n\\nForeign Desk; SECTA\\n72 of Our Favorite Fa...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Times Insider</td>\n",
       "      <td>914</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>72 of Our Favorite Facts From 2023</td>\n",
       "      <td>Document NYTF000020231231ejcv0005r\\n</td>\n",
       "      <td>foreign desk secta 72 favorite fact 2023 time ...</td>\n",
       "      <td>0.054622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[foreign, desk, secta, 72, favorite, fact, 202...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n\\nMoney and Business/Financial Desk; SECTBU\\...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Kashmir Hill</td>\n",
       "      <td>811</td>\n",
       "      <td>Stalker Under Your Hood</td>\n",
       "      <td>The Stalker Under Your Hood</td>\n",
       "      <td>Document NYTF000020231231ejcv0005n\\n</td>\n",
       "      <td>money businessfinancial desk sectbu stalker ho...</td>\n",
       "      <td>0.033175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[money, businessfinancial, desk, sectbu, stalk...</td>\n",
       "      <td>-0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\nBook Review Desk; SECTBR\\nPaperback Row\\n\\...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Shreya Chattopadhyay</td>\n",
       "      <td>431</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Paperback Row</td>\n",
       "      <td>Document NYTF000020231231ejcv0005g\\n</td>\n",
       "      <td>book review desk sectbr paperback row shreya c...</td>\n",
       "      <td>0.127856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[book, review, desk, sectbr, paperback, row, s...</td>\n",
       "      <td>0.003534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n\\nNICHOLAS KRISTOF\\nEditorial Desk; SECTSR\\n...</td>\n",
       "      <td>31 December 2023</td>\n",
       "      <td>Nicholas Kristof</td>\n",
       "      <td>976</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Humans Made Progress In 2023</td>\n",
       "      <td>Document NYTF000020231231ejcv00052\\n</td>\n",
       "      <td>nicholas kristof editorial desk sectsr human m...</td>\n",
       "      <td>0.011590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[nicholas, kristof, editorial, desk, sectsr, h...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article              Date  \\\n",
       "0  \\nMetropolitan Desk; SECTMB\\nCan an Ambitious ...  31 December 2023   \n",
       "1  \\n\\nMagazine Desk; SECTMM\\nWhen Jim Brown and ...  31 December 2023   \n",
       "2  \\n\\nMagazine Desk; SECTMK\\nTalking During Movi...  31 December 2023   \n",
       "3  \\n\\nMagazine Desk; SECTMK\\nLet Kids Vote!\\n\\n4...  31 December 2023   \n",
       "4  \\n\\nMagazine Desk; SECTMK\\nAre We Doomed to Di...  31 December 2023   \n",
       "5  \\n\\nMagazine Desk; SECTMK\\nHello, Fourth Grade...  31 December 2023   \n",
       "6  \\n\\nForeign Desk; SECTA\\n72 of Our Favorite Fa...  31 December 2023   \n",
       "7  \\n\\nMoney and Business/Financial Desk; SECTBU\\...  31 December 2023   \n",
       "8  \\n\\nBook Review Desk; SECTBR\\nPaperback Row\\n\\...  31 December 2023   \n",
       "9  \\n\\nNICHOLAS KRISTOF\\nEditorial Desk; SECTSR\\n...  31 December 2023   \n",
       "\n",
       "                 Auteur  Nombre de mots                  Journal  \\\n",
       "0            Nick Tabor             529           New York Times   \n",
       "1         Wesley Morris             422           New York Times   \n",
       "2                  None             179           New York Times   \n",
       "3                  None             454           New York Times   \n",
       "4       Christina Caron             428           New York Times   \n",
       "5                  None             319           New York Times   \n",
       "6         Times Insider             914           New York Times   \n",
       "7          Kashmir Hill             811  Stalker Under Your Hood   \n",
       "8  Shreya Chattopadhyay             431           New York Times   \n",
       "9      Nicholas Kristof             976           New York Times   \n",
       "\n",
       "                                               Titre  \\\n",
       "0  Copyright 2023 The New York Times Company.  Al...   \n",
       "1  When Jim Brown and Raquel Welch, Two Sexy Star...   \n",
       "2  Talking During Movies: Totally Evil or Part of...   \n",
       "3                                     Let Kids Vote!   \n",
       "4                         Are We Doomed to Disagree?   \n",
       "5  Hello, Fourth Graders! A Look Back at our Clas...   \n",
       "6                 72 of Our Favorite Facts From 2023   \n",
       "7                        The Stalker Under Your Hood   \n",
       "8                                      Paperback Row   \n",
       "9                       Humans Made Progress In 2023   \n",
       "\n",
       "                                      ID  \\\n",
       "0     Document NYTF000020240104ejcv0000d   \n",
       "1     Document NYTF000020231231ejcv0006h   \n",
       "2  Document NYTF000020231231ejcv00064\\n    \n",
       "3  Document NYTF000020231231ejcv00063\\n    \n",
       "4  Document NYTF000020231231ejcv0005z\\n    \n",
       "5  Document NYTF000020231231ejcv0005t\\n    \n",
       "6  Document NYTF000020231231ejcv0005r\\n    \n",
       "7  Document NYTF000020231231ejcv0005n\\n    \n",
       "8  Document NYTF000020231231ejcv0005g\\n    \n",
       "9  Document NYTF000020231231ejcv00052\\n    \n",
       "\n",
       "                                Preprocessed_Article  Sentiment  \\\n",
       "0  metropolitan desk sectmb ambitious public univ...   0.080807   \n",
       "1  magazine desk sectmm jim brown raquel welch tw...   0.096043   \n",
       "2  magazine desk sectmk talking movie totally evi...   0.129610   \n",
       "3  magazine desk sectmk let kid vote 454 word 31 ...   0.068136   \n",
       "4  magazine desk sectmk doomed disagree 428 word ...   0.081156   \n",
       "5  magazine desk sectmk hello fourth grader look ...   0.153341   \n",
       "6  foreign desk secta 72 favorite fact 2023 time ...   0.054622   \n",
       "7  money businessfinancial desk sectbu stalker ho...   0.033175   \n",
       "8  book review desk sectbr paperback row shreya c...   0.127856   \n",
       "9  nicholas kristof editorial desk sectsr human m...   0.011590   \n",
       "\n",
       "   environmental_sentiment_score  \\\n",
       "0                            0.0   \n",
       "1                            0.0   \n",
       "2                            0.0   \n",
       "3                            0.0   \n",
       "4                            0.0   \n",
       "5                            0.0   \n",
       "6                            0.0   \n",
       "7                            0.0   \n",
       "8                            0.0   \n",
       "9                            0.0   \n",
       "\n",
       "                          Preprocessed_Article_split  \\\n",
       "0  [metropolitan, desk, sectmb, ambitious, public...   \n",
       "1  [magazine, desk, sectmm, jim, brown, raquel, w...   \n",
       "2  [magazine, desk, sectmk, talking, movie, total...   \n",
       "3  [magazine, desk, sectmk, let, kid, vote, 454, ...   \n",
       "4  [magazine, desk, sectmk, doomed, disagree, 428...   \n",
       "5  [magazine, desk, sectmk, hello, fourth, grader...   \n",
       "6  [foreign, desk, secta, 72, favorite, fact, 202...   \n",
       "7  [money, businessfinancial, desk, sectbu, stalk...   \n",
       "8  [book, review, desk, sectbr, paperback, row, s...   \n",
       "9  [nicholas, kristof, editorial, desk, sectsr, h...   \n",
       "\n",
       "   environmental_sentiment_score_test  \n",
       "0                            0.000000  \n",
       "1                            0.001267  \n",
       "2                           -0.007692  \n",
       "3                            0.000000  \n",
       "4                            0.000000  \n",
       "5                            0.000000  \n",
       "6                            0.000000  \n",
       "7                           -0.000993  \n",
       "8                            0.003534  \n",
       "9                            0.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['environmental_sentiment_score_test'] = data['Preprocessed_Article_split'].apply(lambda x: get_environmental_score(x, preprocessed_dict_en))\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amélioration du score environnemental => Certains score ne sont pas nul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On essaie de voir maintenant quelles entreprises ont été citées dans le texte :\n",
    "On peut supposer qu'on a une colonne avec toutes les entreprises qui ont été citées dans le texte, ou dans le titre : entr_citées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Preprocessed_Article  \\\n",
      "0   metropolitan desk sectmb ambitious public univ...   \n",
      "1   magazine desk sectmm jim brown raquel welch tw...   \n",
      "2   magazine desk sectmk talking movie totally evi...   \n",
      "3   magazine desk sectmk let kid vote 454 word 31 ...   \n",
      "4   magazine desk sectmk doomed disagree 428 word ...   \n",
      "..                                                ...   \n",
      "95  global health science desk sectd new hope old ...   \n",
      "96  foreign desk secta hotel intended house asylum...   \n",
      "97  businessfinancial desk sectb eu open investiga...   \n",
      "98  trilobite science desk sectd proof wine terroi...   \n",
      "99  impossible energy transition mario loyola 641 ...   \n",
      "\n",
      "                Entreprises_citées  \n",
      "0   imax corp, rh, sun, esi, ateme  \n",
      "1                         igg, esi  \n",
      "2                              igg  \n",
      "3                              esi  \n",
      "4                         igg, esi  \n",
      "..                             ...  \n",
      "95                        cir, esi  \n",
      "96        rh, cir, sun, esi, ateme  \n",
      "97      rh, gem, esi, ateme, atari  \n",
      "98                       benchmark  \n",
      "99                             esi  \n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importer pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le DataFrame des entreprises\n",
    "df_entreprises = pd.read_csv(\"Firms.csv\")\n",
    "\n",
    "# Mettre en minuscules les noms des entreprises\n",
    "df_entreprises['Company'] = df_entreprises['Company'].str.lower()\n",
    "\n",
    "# Copier la colonne 'Preprocessed_Article' du DataFrame 'data' dans un nouveau DataFrame\n",
    "df_articles = data[['Preprocessed_Article']].copy()\n",
    "\n",
    "# Mettre en minuscules le contenu de la colonne 'Preprocessed_Article'\n",
    "df_articles['Preprocessed_Article'] = df_articles['Preprocessed_Article'].apply(lambda x: x.lower())\n",
    "\n",
    "# Initialisation de la nouvelle colonne pour stocker les noms des entreprises citées dans chaque article\n",
    "df_articles['Entreprises_citées'] = ''\n",
    "\n",
    "# Boucle à travers les articles\n",
    "for index, article in df_articles.iterrows():\n",
    "    entreprises_citées = []\n",
    "    contenu_article = article['Preprocessed_Article']\n",
    "    \n",
    "    # Vérifier si le contenu de l'article est une chaîne de caractères\n",
    "    if isinstance(contenu_article, str):\n",
    "        # Vérifier la présence de chaque entreprise dans le contenu de l'article\n",
    "        for index_ent, entreprise in df_entreprises.iterrows():\n",
    "            nom_entreprise = entreprise['Company']\n",
    "            if isinstance(nom_entreprise, str) and nom_entreprise in contenu_article:\n",
    "                entreprises_citées.append(nom_entreprise)\n",
    "    \n",
    "    # Stocker les entreprises citées dans la nouvelle colonne\n",
    "    df_articles.at[index, 'Entreprises_citées'] = ', '.join(entreprises_citées)\n",
    "\n",
    "# Afficher les articles avec les entreprises citées\n",
    "print(df_articles[['Preprocessed_Article', 'Entreprises_citées']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche maintenant à associer à chaque article, une entreprise spécifique (même s'il est cité plusieurs entreprises)\n",
    "\n",
    "On part du principe qu'un article qui ne cite aucune entreprise n'est pas pertinent à étudier => il n'y aurait aucune communication verte\n",
    "Si jamais un article ne cite qu'une seule entreprise, alors il ne peut y avoir (ou pas) communication verte que sur cette entreprise (mais pas de communication verte de plusieurs entreprises dans un seul article)\n",
    "Si jamais il y a plusieurs entreprises citées dans un seul articles, alors on traitera ces données à part, en pensant qu'il peut y avoir plusieurs communications vertes, venant de différentes entreprises, et tout cela dans un seul article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'articles par nombre d'entreprises citées :\n",
      "Nombre_entreprises_citées\n",
      "2     31\n",
      "1     26\n",
      "3     17\n",
      "5     13\n",
      "4     10\n",
      "6      1\n",
      "10     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Résumé du nombre d'articles par nombre d'entreprises citées :\n",
      "Aucune entreprise citée : 0\n",
      "1 entreprise(s) citée(s) : 26\n",
      "2 entreprise(s) citée(s) : 31\n",
      "3 entreprise(s) citée(s) : 17\n",
      "4 entreprise(s) citée(s) : 10\n",
      "5 entreprise(s) citée(s) : 13\n",
      "6 entreprise(s) citée(s) : 1\n",
      "7 entreprise(s) citée(s) : 0\n",
      "8 entreprise(s) citée(s) : 0\n",
      "9 entreprise(s) citée(s) : 0\n",
      "10 entreprise(s) citée(s) : 1\n"
     ]
    }
   ],
   "source": [
    "# Ajouter une colonne pour le nombre d'entreprises citées dans chaque article\n",
    "df_articles['Nombre_entreprises_citées'] = df_articles['Entreprises_citées'].apply(lambda x: x.count(',') + 1)\n",
    "\n",
    "# Compter le nombre d'articles par nombre d'entreprises citées\n",
    "comptage_entreprises = df_articles['Nombre_entreprises_citées'].value_counts()\n",
    "\n",
    "# Afficher le comptage des articles par nombre d'entreprises citées\n",
    "print(\"Nombre d'articles par nombre d'entreprises citées :\")\n",
    "print(comptage_entreprises)\n",
    "\n",
    "# Afficher le nombre d'articles qui ne citent aucune entreprise, qui en citent une seule, etc.\n",
    "print(\"\\nRésumé du nombre d'articles par nombre d'entreprises citées :\")\n",
    "print(\"Aucune entreprise citée :\", comptage_entreprises.get(0, 0))\n",
    "for i in range(1, max(comptage_entreprises.index) + 1):\n",
    "    print(f\"{i} entreprise(s) citée(s) :\", comptage_entreprises.get(i, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Titre_article'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Affichage des articles avec une seule entreprise citée\u001b[39;00m\n\u001b[1;32m      8\u001b[0m articles_avec_entreprise_unique \u001b[38;5;241m=\u001b[39m df_articles[df_articles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntreprise_unique\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43marticles_avec_entreprise_unique\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTitre_article\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEntreprise_unique\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/pandas/core/indexes/base.py:6199\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6197\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6201\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6203\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/pandas/core/indexes/base.py:6251\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6250\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Titre_article'] not in index\""
     ]
    }
   ],
   "source": [
    "# Suppression des données sans entreprises citées\n",
    "df_articles = df_articles[df_articles['Entreprises_citées'] != '']\n",
    "\n",
    "# Identification des articles avec une seule entreprise citée\n",
    "df_articles['Entreprise_unique'] = df_articles['Entreprises_citées'].apply(lambda x: x.split(',')[0] if ',' not in x else '')\n",
    "\n",
    "# Affichage des articles avec une seule entreprise citée\n",
    "articles_avec_entreprise_unique = df_articles[df_articles['Entreprise_unique'] != '']\n",
    "print(articles_avec_entreprise_unique[['Titre_article', 'Entreprise_unique']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkb1ZHzje3fw"
   },
   "source": [
    "Si on a une base de données qui contient un certain nomre d'articles deja labellisés avec une note environnementale, on pourrait entrainer un modèle de machine learning plus traditionnel que de l'analyse de sentiment.\n",
    "\n",
    "en effet, on peut passer par de la vectorization des mots par TF-IDF (ou autre - à voir), puis entrainer un modèle de régression linéaire (ou autre - à voir), et prédire pour les nouveaux articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYxpksZle1d_"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(dataset['text'])  # 'texts' is the column with your text data\n",
    "y = dataset['scores']  # 'scores' is the column with your positivity scores\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "new_text = vectorizer.transform([\"New text\"])\n",
    "new_score = model.predict(new_text)\n",
    "print(f'Predicted Sentiment Score: {new_score}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
